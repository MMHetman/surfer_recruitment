{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "hGlp2USa98Z7",
    "outputId": "2ba94bdd-c6f3-4f06-8318-7a24b53730f2"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scrape_id</th>\n",
       "      <th>scrape_keyword</th>\n",
       "      <th>crawled_page_id</th>\n",
       "      <th>crawled_page_url</th>\n",
       "      <th>words</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>244568</td>\n",
       "      <td>seo course 2020</td>\n",
       "      <td>3242198</td>\n",
       "      <td>https://www.quicksprout.com/best-seo-courses-a...</td>\n",
       "      <td>[\"our\", \"content\", \"is\", \"reader\", \"supported\"...</td>\n",
       "      <td>[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>244568</td>\n",
       "      <td>seo course 2020</td>\n",
       "      <td>3242200</td>\n",
       "      <td>https://digitaldefynd.com/best-seo-courses-tra...</td>\n",
       "      <td>[\"skip\", \"to\", \"content\", \"trending\", \"10\", \"b...</td>\n",
       "      <td>[3, 3, 3, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>244568</td>\n",
       "      <td>seo course 2020</td>\n",
       "      <td>3242201</td>\n",
       "      <td>https://www.trumplearning.com/best-seo-course-...</td>\n",
       "      <td>[\"toggle\", \"navigation\", \"contact\", \"us\", \"hom...</td>\n",
       "      <td>[6, 6, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244568</td>\n",
       "      <td>seo course 2020</td>\n",
       "      <td>3242199</td>\n",
       "      <td>https://ippei.com/best-seo-course/</td>\n",
       "      <td>[\"currently\", \"set\", \"to\", \"index\", \"currently...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 10, 10, 10, 7, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>244568</td>\n",
       "      <td>seo course 2020</td>\n",
       "      <td>3242195</td>\n",
       "      <td>https://www.searchenginejournal.com/best-free-...</td>\n",
       "      <td>[\"seo\", \"all\", \"seo\", \"ask\", \"an\", \"seo\", \"beg...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scrape_id   scrape_keyword  crawled_page_id  \\\n",
       "0     244568  seo course 2020          3242198   \n",
       "1     244568  seo course 2020          3242200   \n",
       "2     244568  seo course 2020          3242201   \n",
       "3     244568  seo course 2020          3242199   \n",
       "4     244568  seo course 2020          3242195   \n",
       "\n",
       "                                    crawled_page_url  \\\n",
       "0  https://www.quicksprout.com/best-seo-courses-a...   \n",
       "1  https://digitaldefynd.com/best-seo-courses-tra...   \n",
       "2  https://www.trumplearning.com/best-seo-course-...   \n",
       "3                 https://ippei.com/best-seo-course/   \n",
       "4  https://www.searchenginejournal.com/best-free-...   \n",
       "\n",
       "                                               words  \\\n",
       "0  [\"our\", \"content\", \"is\", \"reader\", \"supported\"...   \n",
       "1  [\"skip\", \"to\", \"content\", \"trending\", \"10\", \"b...   \n",
       "2  [\"toggle\", \"navigation\", \"contact\", \"us\", \"hom...   \n",
       "3  [\"currently\", \"set\", \"to\", \"index\", \"currently...   \n",
       "4  [\"seo\", \"all\", \"seo\", \"ask\", \"an\", \"seo\", \"beg...   \n",
       "\n",
       "                                              scores  \n",
       "0  [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...  \n",
       "1  [3, 3, 3, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2  [6, 6, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 10, 10, 10, 7, 7, 7, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('scrapes.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "raG4pGK2BBGP",
    "outputId": "53412077-db31-45a3-9311-7228a1319a93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3464\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "complex_terms = 0\n",
    "inconsistent_scores = 0\n",
    "empty_words = 0\n",
    "empty_words_list = 0\n",
    "for index, row in dataset.iterrows():\n",
    "    words = ast.literal_eval(row['words'])\n",
    "    words = [n.strip() for n in words]\n",
    "    scores = ast.literal_eval(row['scores'])\n",
    "    broken_indices = set()\n",
    "    for i in range(len(words)):\n",
    "      words[i] = words[i].strip()\n",
    "      if ' ' in words[i]:\n",
    "        complex_terms += 1\n",
    "        broken_indices.add(i)\n",
    "      if not words[i]:\n",
    "        empty_words += 1\n",
    "        broken_indices.add(i)\n",
    "    for i in sorted(broken_indices, reverse=True):\n",
    "      del words[i]\n",
    "      del scores[i]\n",
    "    dataset.at[index, 'words'] = str(words)\n",
    "    dataset.at[index, 'scores'] = str(scores)\n",
    "    if len(words) != len(scores):\n",
    "      inconsistent_scores += 1\n",
    "      dataset.drop(index, inplace=True)\n",
    "    elif len(words) == 0:\n",
    "      empty_words_list += 1\n",
    "      dataset.drop(index, inplace=True)\n",
    "print(complex_terms)\n",
    "print(inconsistent_scores)\n",
    "print(empty_words)\n",
    "print(empty_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_phrases(words, scores, scrape_id):\n",
    "  phrases = []\n",
    "  for i in range(len(words)):\n",
    "    phrase = []\n",
    "    score_sum = 0\n",
    "    for j in range(4):\n",
    "      if i + j >= len(words):\n",
    "        continue\n",
    "      phrase.append(words[i+j])\n",
    "      score_sum += scores[i + j]\n",
    "      phrases.append((scrape_id, ' '.join(phrase), score_sum/(j+1)))\n",
    "  return phrases\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kGsu0QkMKMFb"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "scrape_ids = set(dataset['scrape_id'])\n",
    "phrases_data = []\n",
    "for id in scrape_ids:\n",
    "  subframe = dataset[dataset['scrape_id'] == id]\n",
    "  for index, row in subframe.iterrows():\n",
    "    words = ast.literal_eval(row['words'])\n",
    "    words = [n.strip() for n in words]\n",
    "    scores = ast.literal_eval(row['scores'])\n",
    "    phrases_data += get_phrases(words, scores, id)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wkj8QaYJhAc6"
   },
   "outputs": [],
   "source": [
    "phrases_df = pd.DataFrame(phrases_data, columns=['scrape_id', 'phrase', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_R4STKkmWpcJ"
   },
   "outputs": [],
   "source": [
    "def get_tfidfs_dataframe(phrases_df):\n",
    "    terms_scores_sum_per_scrape = phrases_df.groupby(['scrape_id', 'phrase']).sum().sort_values(by = 'score', ascending=False).reset_index()\n",
    "    sum_scores_per_scrape = terms_scores_sum_per_scrape.groupby(['scrape_id']).sum().sort_values(by = 'score', ascending=False).reset_index()\n",
    "    sum_scores_per_scrape.rename(columns = {'score': 'score_sum'}, inplace = True)\n",
    "    phrases_freq = terms_scores_sum_per_scrape.join(other = sum_scores_per_scrape.set_index('scrape_id'), on = 'scrape_id')\n",
    "    phrases_freq['pf'] = phrases_freq.score / phrases_freq.score_sum\n",
    "\n",
    "    inverse_document_frequency = terms_scores_sum_per_scrape[['phrase', 'scrape_id']].groupby(['phrase']).count().sort_values(by = 'scrape_id', ascending=False).reset_index().rename(columns = {'scrape_id': 'occurances'})\n",
    "    inverse_document_frequency['idf'] = len(set(dataset['scrape_id'])) / inverse_document_frequency.occurances\n",
    "    inverse_document_frequency['idf'] = inverse_document_frequency['idf'].apply(math.log)\n",
    "\n",
    "    tfidfs = phrases_freq.join(other = inverse_document_frequency.set_index('phrase'), on = 'phrase')\n",
    "    tfidfs['tfidf'] = tfidfs.pf * tfidfs.idf\n",
    "    return tfidfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t8Sna8KMOCGu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tfidfs1 = get_tfidfs_dataframe(phrases_df)\n",
    "tfidfs1 = tfidfs1.groupby('scrape_id').apply(lambda x: x.nlargest(10, 'tfidf')).reset_index(drop=True).join(dataset[['scrape_id', 'scrape_keyword']].drop_duplicates().set_index('scrape_id'), on = 'scrape_id')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
